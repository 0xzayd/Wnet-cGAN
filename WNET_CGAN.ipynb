{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "from keras.optimizers import adam\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.layers import Input, AveragePooling2D, MaxPooling2D, Dropout, Lambda, AlphaDropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    # net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wnet(inp_dsm, inp_pan, blocks_list, k_size, activation, n_labels=1, name=None):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        n_labels, int, number of labels = 1\n",
    "        blocks list, list, number of filters in each block\n",
    "        k_size, tuple, filter size\n",
    "        activation, string, activation function\n",
    "        \n",
    "    output:\n",
    "        keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # PAN\n",
    "    \n",
    "    k_init = 'lecun_normal'\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        concat_axis = 1\n",
    "    else:\n",
    "        concat_axis = 3\n",
    "        \n",
    "    encoder_pan = inp_pan\n",
    "    \n",
    "    list_encoders = []\n",
    "    \n",
    "    print('Building Unet for PAN Image')\n",
    "    print(blocks_list)   \n",
    "    \n",
    "    with K.name_scope('PAN_UNet'):\n",
    "        for l_idx, n_ch in enumerate(blocks_list):\n",
    "            with K.name_scope('Encoder_block_{0}'.format(l_idx)):\n",
    "                encoder_pan = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(encoder_pan)\n",
    "                encoder_pan = AlphaDropout(0.1*l_idx, )(encoder_pan)\n",
    "                encoder_pan = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 dilation_rate=(2, 2),\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(encoder_pan)\n",
    "                list_encoders.append(encoder_pan)\n",
    "                # add maxpooling layer except the last layer\n",
    "                if l_idx < len(blocks_list) - 1:\n",
    "                    encoder_pan = MaxPooling2D(pool_size=(2,2))(encoder_pan)\n",
    "                # if use_tfboard:\n",
    "                    # tf.summary.histogram('conv_encoder', encoder)\n",
    "        # decoders\n",
    "        decoder_pan = encoder_pan\n",
    "        dec_n_ch_list = blocks_list[::-1][1:]\n",
    "        print(dec_n_ch_list)\n",
    "        for l_idx, n_ch in enumerate(dec_n_ch_list):\n",
    "            with K.name_scope('Decoder_block_{0}'.format(l_idx)):\n",
    "                l_idx_rev = len(blocks_list) - 1 - l_idx\n",
    "                decoder_pan = concatenate([decoder_pan, list_encoders[l_idx_rev]], axis=concat_axis)\n",
    "                decoder_pan = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 dilation_rate=(2, 2),\n",
    "                                 kernel_initializer=k_init)(decoder_pan)\n",
    "                decoder_pan = AlphaDropout(0.1*l_idx, )(decoder_pan)\n",
    "                decoder_pan = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(decoder_pan)\n",
    "                decoder_pan = Conv2DTranspose(filters=n_ch,\n",
    "                                          kernel_size=k_size,\n",
    "                                          strides=(2, 2), \n",
    "                                          activation=activation,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=k_init)(decoder_pan)\n",
    "\n",
    "        # output layer should be softmax\n",
    "        outp_pan = Conv2DTranspose(filters=n_labels,\n",
    "                               kernel_size=k_size,\n",
    "                               activation='sigmoid',\n",
    "                               padding='same',\n",
    "                               kernel_initializer='glorot_normal')(decoder_pan)\n",
    "    \n",
    "    ### DSM\n",
    "    \n",
    "    encoder_dsm = inp_dsm\n",
    "    \n",
    "    list_encoders_dsm = []\n",
    "    \n",
    "    print('Building Unet for DSM')\n",
    "    print(blocks_list)   \n",
    "    \n",
    "    with K.name_scope('DSM_UNet'):\n",
    "        for l_idx, n_ch in enumerate(blocks_list):\n",
    "            with K.name_scope('Encoder_block_{0}'.format(l_idx)):\n",
    "                encoder_dsm = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(encoder_dsm)\n",
    "                encoder_dsm = AlphaDropout(0.1*l_idx, )(encoder_dsm)\n",
    "                encoder_dsm = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 dilation_rate=(2, 2),\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(encoder_dsm)\n",
    "                list_encoders_dsm.append(encoder_dsm)\n",
    "                # add maxpooling layer except the last layer\n",
    "                if l_idx < len(blocks_list) - 1:\n",
    "                    encoder_dsm = MaxPooling2D(pool_size=(2,2))(encoder_dsm)\n",
    "                # if use_tfboard:\n",
    "                    # tf.summary.histogram('conv_encoder', encoder)\n",
    "        # decoders\n",
    "        decoder_dsm = encoder_dsm\n",
    "        dec_n_ch_list = blocks_list[::-1][1:]\n",
    "        print(dec_n_ch_list)\n",
    "        for l_idx, n_ch in enumerate(dec_n_ch_list):\n",
    "            with K.name_scope('Decoder_block_{0}'.format(l_idx)):\n",
    "                l_idx_rev = len(blocks_list) - 1 - l_idx\n",
    "                decoder_dsm = concatenate([decoder_dsm, list_encoders[l_idx_rev]], axis=concat_axis)\n",
    "                decoder_dsm = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 dilation_rate=(2, 2),\n",
    "                                 kernel_initializer=k_init)(decoder_dsm)\n",
    "                decoder_dsm = AlphaDropout(0.1*l_idx, )(decoder_dsm)\n",
    "                decoder_dsm = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(decoder_dsm)\n",
    "                decoder_dsm = Conv2DTranspose(filters=n_ch,\n",
    "                                          kernel_size=k_size,\n",
    "                                          strides=(2, 2), \n",
    "                                          activation=activation,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=k_init)(decoder_dsm)\n",
    "        \n",
    "        # output layer should be softmax\n",
    "        outp_dsm = Conv2DTranspose(filters=n_labels,\n",
    "                               kernel_size=k_size,\n",
    "                               activation='sigmoid',\n",
    "                               padding='same',\n",
    "                               kernel_initializer='glorot_normal')(decoder_dsm)\n",
    "        \n",
    "        outp = concatenate([outp_dsm, outp_pan], axis=concat_axis)\n",
    "        outp = Conv2D(filters=1, kernel_size=(1,1), padding='same', kernel_initializer='lecun_normal')(outp)\n",
    "\n",
    "    return Model(inputs=[inp_dsm,inp_pan], outputs=[outp], name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscriminatorNet(inp_DSM, inp_Label, block_list, activation, k_size=(3,3), inputs_ch=64, name='DISCR'):\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        concat_axis = 1\n",
    "    else:\n",
    "        concat_axis = 3\n",
    "\n",
    "    k_init = 'lecun_normal'\n",
    "    with K.name_scope('DiscriminatorNet'):\n",
    "        with K.name_scope('DSM_input_conv'):\n",
    "            X = Conv2D(filters=inputs_ch,\n",
    "                       kernel_size=(1,1),\n",
    "                       activation=activation,\n",
    "                       padding='same',\n",
    "                       kernel_initializer=k_init)(inp_DSM)\n",
    "        with K.name_scope('Label_input_conv'):  \n",
    "            Y = Conv2D(filters=inputs_ch,\n",
    "                       kernel_size=(1,1),\n",
    "                       activation=activation,\n",
    "                       padding='same',\n",
    "                       kernel_initializer=k_init)(inp_Label)\n",
    "            \n",
    "        encoder = concatenate([X, Y], axis=concat_axis) \n",
    "        for l_idx, n_ch in enumerate(block_list):  #something like [32,32,32,32,32]\n",
    "            with K.name_scope('Discr_block_{0}'.format(l_idx)):\n",
    "                encoder = Conv2D(filters=n_ch,\n",
    "                                 kernel_size=k_size,\n",
    "                                 activation=activation,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=k_init)(encoder)\n",
    "                # encoder = AlphaDropout(0.1*l_idx, )(encoder)\n",
    "                # add maxpooling layer except the last layer\n",
    "                if l_idx < len(block_list) - 1:\n",
    "                    encoder = MaxPooling2D(pool_size=(2,2))(encoder)\n",
    "        encoder = Flatten()(encoder)\n",
    "        outp = Dense(1, activation='sigmoid')(encoder)\n",
    "    \n",
    "    return Model(inputs=[inp_DSM, inp_Label], outputs=outp, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wnet_cgan:\n",
    "    def __init__(self,\n",
    "                 height, \n",
    "                 width,\n",
    "                 n_labels=1):\n",
    "        \n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (1, height, width) #define laebl_shape separately in case of multiple labels of roof\n",
    "            concat_axis = 1\n",
    "        else:\n",
    "            input_shape = (height, width, 1)\n",
    "            concat_axis = 3\n",
    "            \n",
    "        self.pan_shape = self.dsm_shape = self.label_shape = input_shape\n",
    "        self.init_epoch = 0\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "    def build_wnet_cgan(self,\n",
    "                        wnet_block_list,\n",
    "                        wnet_k_size, \n",
    "                        wnet_activation='selu',\n",
    "                        wnet_lr=1e-4,\n",
    "                        discr_inp_channels = 64,\n",
    "                        discr_block_list=[32,32,32,32,32],\n",
    "                        discr_k_size=(3,3), \n",
    "                        discr_activation='relu',\n",
    "                        discr_lr=1e-4,\n",
    "                        lambda_=1e-1):\n",
    "        inp_dsm = Input(self.dsm_shape, name='dsm_input')\n",
    "        inp_pan = Input(self.pan_shape, name='pan_input')\n",
    "        inp_label = Input(self.label_shape, name='label_input')\n",
    "\n",
    "        wnet_opt = adam(lr=wnet_lr)\n",
    "        discr_opt = adam(lr=discr_lr)\n",
    "\n",
    "        # build the Discriminator\n",
    "        print('Build discr')\n",
    "        self.discriminator = DiscriminatorNet(inp_dsm,\n",
    "                                              inp_label,\n",
    "                                              discr_block_list,\n",
    "                                              discr_activation,\n",
    "                                              discr_k_size,\n",
    "                                              discr_inp_channels,\n",
    "                                              'Discriminator')\n",
    "        print('Done')\n",
    "        # make Discriminator untrainable and copy it to 'frozen Discriminator' (like pyTorch's detach()?!)\n",
    "        make_trainable(self.discriminator, False)\n",
    "\n",
    "        frozen_discriminator = Model(inputs=self.discriminator.inputs,\n",
    "                                     outputs=self.discriminator.outputs,\n",
    "                                     name='frozen_discriminator')\n",
    "        frozen_discriminator.compile(discr_opt,\n",
    "                                     loss = 'binary_crossentropy',\n",
    "                                     metrics=['accuracy'])\n",
    "        #print('Frozen and compiled')\n",
    "        # build the wnet\n",
    "        #print('Build Wnet')\n",
    "        self.wnet = Wnet(inp_dsm, \n",
    "                         inp_pan, \n",
    "                         wnet_block_list, \n",
    "                         wnet_k_size, \n",
    "                         wnet_activation, \n",
    "                         self.n_labels, \n",
    "                         name='Wnet')\n",
    "\n",
    "        #compile the wnet\n",
    "        self.wnet.compile(wnet_opt,\n",
    "                          loss = 'binary_crossentropy',\n",
    "                          metrics=['accuracy'])  # CHANGE TO mIoU !!!!!!!!\n",
    "\n",
    "        #print('Compiled Wnet') \n",
    "        # get the wnet prediction\n",
    "        pred = self.wnet([inp_dsm, inp_pan])\n",
    "        #print('got pred from Wnet')\n",
    "        # input the prediction into the frozen discriminator and get the probability fake/real\n",
    "        prob = frozen_discriminator([inp_dsm, pred])\n",
    "        #print('got prob from frozen Discr')\n",
    "        # stack wnet and discriminator to form the Wnet-CGAN\n",
    "        #print('stacking the two')\n",
    "        self.wnet_cgan = Model(inputs=[inp_dsm, inp_pan, inp_label],\n",
    "                               outputs=[pred, prob],\n",
    "                               name='WNet-CGAN')\n",
    "        #print('stacked')\n",
    "        # compile it\n",
    "        #print('compiling the stcaked')\n",
    "        self.wnet_cgan.compile(wnet_opt,\n",
    "                               loss=['binary_crossentropy', 'binary_crossentropy'],\n",
    "                               loss_weights=[1., lambda_],\n",
    "                               metrics=['accuracy'])\n",
    "        #print('compiled')\n",
    "        #print(wnet_cgan.summary())\n",
    "\n",
    "        # compile the discriminator\n",
    "        make_trainable(self.discriminator, True)\n",
    "        self.discriminator.compile(discr_opt,\n",
    "                                   loss='binary_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        #print(self.discriminator.summary())\n",
    "            \n",
    "    def fit_wnet_cgan(self,\n",
    "                      X,\n",
    "                      Y,\n",
    "                      adv_epochs=10,\n",
    "                      adv_steps_epoch=100,\n",
    "                      gen_epochs=20,\n",
    "                      gen_steps_epoch=100,\n",
    "                      validation_steps=4,\n",
    "                      n_rounds=10):\n",
    "\n",
    "        discr_callbacks = self.build_callbacks()\n",
    "        gen_callbacks = self.build_callbacks()\n",
    "              \n",
    "        for i in range(n_rounds):\n",
    "            #train discriminator first\n",
    "            #self.discriminator.fit(x=discr_X, \n",
    "                                   #y=discr_Y,\n",
    "                                   #epochs=(i+1)*adv_epochs,\n",
    "                                   #callbacks=discr_callbacks,\n",
    "                                   #validation_split=0.2,\n",
    "                                   #validation_steps=validation_steps,\n",
    "                                   #shuffle=True,\n",
    "                                   #steps_per_epoch=adv_steps_epoch,\n",
    "                                   #initial_epoch=i*adv_epochs,\n",
    "                                   #verbose=0)\n",
    "            \n",
    "            self.wnet_cgan.fit(x=X,\n",
    "                               y=Y,\n",
    "                               epochs=(i+1)*gen_epochs,\n",
    "                               callbacks=gen_callbacks,\n",
    "                               validation_split=0.2,\n",
    "                               validation_steps=validation_steps,\n",
    "                               shuffle=True,\n",
    "                               steps_per_epoch=gen_steps_epoch,\n",
    "                               initial_epoch=i*gen_epochs,\n",
    "                               verbose=1)\n",
    "            \n",
    "            # Sub training-dataset for disciminator\n",
    "            pred = self.wnet.predict([X[0],X[1]])\n",
    "            discr_X_1, discr_X_2 = np.concatenate((X[0],X[0]), axis=0), np.concatenate((X[2],pred), axis=0)\n",
    "            discr_Y = np.concatenate((Y[1],np.ones(shape=(len(pred),1))),axis=0)\n",
    "            \n",
    "            discr_X_1, discr_X2, discr_Y = shuffle(discr_X_1, discr_X_2, discr_Y, random_state=42)\n",
    "            discr_X = [discr_X_1, discr_X_2]\n",
    "            \n",
    "            \n",
    "            # train discriminator last\n",
    "            self.discriminator.fit(x=discr_X, \n",
    "                                   y=discr_Y,\n",
    "                                   epochs=(i+1)*adv_epochs,\n",
    "                                   callbacks=discr_callbacks,\n",
    "                                   validation_split=0.2,\n",
    "                                   validation_steps=validation_steps,\n",
    "                                   shuffle=True,\n",
    "                                   steps_per_epoch=adv_steps_epoch,\n",
    "                                   initial_epoch=i*adv_epochs,\n",
    "                                   verbose=0)\n",
    "            \n",
    "            \n",
    "    def build_callbacks(self, log_dir = None):\n",
    "\n",
    "        # Tensorboard\n",
    "        log_dir = './logs'\n",
    "        tensorboard = TrainValTensorBoard(log_dir = log_dir)\n",
    "        path = './results'\n",
    "        \n",
    "        \n",
    "        # Model Checkpoints\n",
    "        filepath=path + \"/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "        #filepath=self.path + \"/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "        \n",
    "        # Bring all the callbacks together into a python list\n",
    "        self.callbackList = [tensorboard, checkpoint]        \n",
    "            \n",
    "    #def build_callbacks(self, use_tfboard=True, monitor=None, phase=None, save=True):\n",
    "        \n",
    "        #path = './results'\n",
    "\n",
    "        # Model Checkpoints\n",
    "        #if monitor is None:\n",
    "            #callbackList = []\n",
    "        #else:\n",
    "            #if not os.path.exists(path):\n",
    "                #os.makedirs(path)\n",
    "            #filepath=path+'/weights-{epoch:02d}-{'+'{0}'.format(monitor)+':.2f}.hdf5'\n",
    "            #checkpoint = ModelCheckpoint(filepath,\n",
    "                                         #monitor=monitor,\n",
    "                                         #verbose=1,\n",
    "                                         #save_best_only=save,\n",
    "                                         #save_weights_only=save,\n",
    "                                         #mode='max')\n",
    "\n",
    "            # Bring all the callbacks together into a python list\n",
    "            #callbackList = [checkpoint]\n",
    "                    \n",
    "        # Tensorboard\n",
    "        #if use_tfboard:\n",
    "            #if phase is None:\n",
    "                #tfpath = './logs'\n",
    "            #else:\n",
    "                #tfpath = './logs/{0}'.format(phase)\n",
    "            #tensorboard = TrainValTensorBoard(log_dir=tfpath)\n",
    "            #callbackList.append(tensorboard)\n",
    "        #return callbackList\n",
    "    \n",
    "    \n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', hist_freq=0, **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, histogram_freq=hist_freq, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan = np.random.rand(10,32,32,1)\n",
    "dsm = np.random.randint(2,size=(10,32,32,1))\n",
    "label = np.copy(pan)\n",
    "label[label>=0.4] = 1\n",
    "label[label<0.4] = 0\n",
    "label = label * dsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = Wnet_cgan(32, 32, n_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build discr\n",
      "Done\n",
      "Building Unet for PAN Image\n",
      "[32, 32, 32]\n",
      "[32, 32]\n",
      "Building Unet for DSM\n",
      "[32, 32, 32]\n",
      "[32, 32]\n"
     ]
    }
   ],
   "source": [
    "myModel.build_wnet_cgan([32,32,32],\n",
    "                        (3,3), \n",
    "                        wnet_activation='selu',\n",
    "                        wnet_lr=1e-4,\n",
    "                        discr_inp_channels = 16,\n",
    "                        discr_block_list=[32,32,32,32],\n",
    "                        discr_k_size=(3,3), \n",
    "                        discr_activation='relu',\n",
    "                        discr_lr=1e-4,\n",
    "                        lambda_=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\tfenv\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 0.8342 - Wnet_loss: 0.7562 - frozen_discriminator_loss: 0.7807 - Wnet_acc: 0.6172 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7060 - val_Wnet_loss: 0.6263 - val_frozen_discriminator_loss: 0.7970 - val_Wnet_acc: 0.6909 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7101 - Wnet_loss: 0.6321 - frozen_discriminator_loss: 0.7796 - Wnet_acc: 0.6825 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6973 - val_Wnet_loss: 0.6181 - val_frozen_discriminator_loss: 0.7915 - val_Wnet_acc: 0.6973 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6956 - Wnet_loss: 0.6177 - frozen_discriminator_loss: 0.7785 - Wnet_acc: 0.6943 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6951 - val_Wnet_loss: 0.6159 - val_frozen_discriminator_loss: 0.7919 - val_Wnet_acc: 0.6987 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6903 - Wnet_loss: 0.6125 - frozen_discriminator_loss: 0.7773 - Wnet_acc: 0.6965 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6950 - val_Wnet_loss: 0.6158 - val_frozen_discriminator_loss: 0.7921 - val_Wnet_acc: 0.6987 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6872 - Wnet_loss: 0.6095 - frozen_discriminator_loss: 0.7773 - Wnet_acc: 0.6977 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6960 - val_Wnet_loss: 0.6169 - val_frozen_discriminator_loss: 0.7912 - val_Wnet_acc: 0.6987 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6841 - Wnet_loss: 0.6064 - frozen_discriminator_loss: 0.7767 - Wnet_acc: 0.6981 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6975 - val_Wnet_loss: 0.6184 - val_frozen_discriminator_loss: 0.7907 - val_Wnet_acc: 0.6968 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6812 - Wnet_loss: 0.6036 - frozen_discriminator_loss: 0.7763 - Wnet_acc: 0.6986 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.6988 - val_Wnet_loss: 0.6199 - val_frozen_discriminator_loss: 0.7893 - val_Wnet_acc: 0.6963 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6787 - Wnet_loss: 0.6012 - frozen_discriminator_loss: 0.7758 - Wnet_acc: 0.6989 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7013 - val_Wnet_loss: 0.6224 - val_frozen_discriminator_loss: 0.7890 - val_Wnet_acc: 0.6948 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6758 - Wnet_loss: 0.5983 - frozen_discriminator_loss: 0.7750 - Wnet_acc: 0.6993 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7032 - val_Wnet_loss: 0.6243 - val_frozen_discriminator_loss: 0.7892 - val_Wnet_acc: 0.6934 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6723 - Wnet_loss: 0.5949 - frozen_discriminator_loss: 0.7742 - Wnet_acc: 0.7001 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7057 - val_Wnet_loss: 0.6266 - val_frozen_discriminator_loss: 0.7920 - val_Wnet_acc: 0.6875 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6838 - Wnet_loss: 0.6062 - frozen_discriminator_loss: 0.7762 - Wnet_acc: 0.6898 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7114 - val_Wnet_loss: 0.6315 - val_frozen_discriminator_loss: 0.7989 - val_Wnet_acc: 0.6987 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6761 - Wnet_loss: 0.5985 - frozen_discriminator_loss: 0.7760 - Wnet_acc: 0.6994 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7033 - val_Wnet_loss: 0.6240 - val_frozen_discriminator_loss: 0.7925 - val_Wnet_acc: 0.6943 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.6721 - Wnet_loss: 0.5947 - frozen_discriminator_loss: 0.7745 - Wnet_acc: 0.6995 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7068 - val_Wnet_loss: 0.6277 - val_frozen_discriminator_loss: 0.7905 - val_Wnet_acc: 0.6904 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.6667 - Wnet_loss: 0.5894 - frozen_discriminator_loss: 0.7733 - Wnet_acc: 0.7010 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7076 - val_Wnet_loss: 0.6287 - val_frozen_discriminator_loss: 0.7894 - val_Wnet_acc: 0.6855 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6624 - Wnet_loss: 0.5851 - frozen_discriminator_loss: 0.7725 - Wnet_acc: 0.7019 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7097 - val_Wnet_loss: 0.6308 - val_frozen_discriminator_loss: 0.7895 - val_Wnet_acc: 0.6821 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6562 - Wnet_loss: 0.5790 - frozen_discriminator_loss: 0.7721 - Wnet_acc: 0.7044 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7087 - val_Wnet_loss: 0.6295 - val_frozen_discriminator_loss: 0.7918 - val_Wnet_acc: 0.6846 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6488 - Wnet_loss: 0.5716 - frozen_discriminator_loss: 0.7718 - Wnet_acc: 0.7073 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7244 - val_Wnet_loss: 0.6455 - val_frozen_discriminator_loss: 0.7894 - val_Wnet_acc: 0.6787 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6396 - Wnet_loss: 0.5625 - frozen_discriminator_loss: 0.7714 - Wnet_acc: 0.7116 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7404 - val_Wnet_loss: 0.6614 - val_frozen_discriminator_loss: 0.7897 - val_Wnet_acc: 0.6768 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6289 - Wnet_loss: 0.5518 - frozen_discriminator_loss: 0.7702 - Wnet_acc: 0.7167 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.7891 - val_Wnet_loss: 0.7100 - val_frozen_discriminator_loss: 0.7904 - val_Wnet_acc: 0.6807 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6202 - Wnet_loss: 0.5432 - frozen_discriminator_loss: 0.7701 - Wnet_acc: 0.7217 - frozen_discriminator_acc: 0.0000e+00 - val_loss: 0.8048 - val_Wnet_loss: 0.7259 - val_frozen_discriminator_loss: 0.7888 - val_Wnet_acc: 0.6821 - val_frozen_discriminator_acc: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5320 - Wnet_loss: 0.5320 - frozen_discriminator_loss: 7.8417e-07 - Wnet_acc: 0.7273 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7489 - val_Wnet_loss: 0.7489 - val_frozen_discriminator_loss: 8.9407e-07 - val_Wnet_acc: 0.6675 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.5327 - Wnet_loss: 0.5327 - frozen_discriminator_loss: 7.7680e-07 - Wnet_acc: 0.7265 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7352 - val_Wnet_loss: 0.7352 - val_frozen_discriminator_loss: 8.9407e-07 - val_Wnet_acc: 0.6611 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.5176 - Wnet_loss: 0.5176 - frozen_discriminator_loss: 7.3455e-07 - Wnet_acc: 0.7366 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7274 - val_Wnet_loss: 0.7274 - val_frozen_discriminator_loss: 7.1526e-07 - val_Wnet_acc: 0.6611 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.5093 - Wnet_loss: 0.5093 - frozen_discriminator_loss: 6.7972e-07 - Wnet_acc: 0.7412 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7835 - val_Wnet_loss: 0.7835 - val_frozen_discriminator_loss: 7.1526e-07 - val_Wnet_acc: 0.6611 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5021 - Wnet_loss: 0.5021 - frozen_discriminator_loss: 7.0378e-07 - Wnet_acc: 0.7471 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7759 - val_Wnet_loss: 0.7759 - val_frozen_discriminator_loss: 1.0729e-06 - val_Wnet_acc: 0.6748 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4996 - Wnet_loss: 0.4996 - frozen_discriminator_loss: 6.4239e-07 - Wnet_acc: 0.7475 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7667 - val_Wnet_loss: 0.7667 - val_frozen_discriminator_loss: 8.9407e-07 - val_Wnet_acc: 0.6748 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4924 - Wnet_loss: 0.4924 - frozen_discriminator_loss: 7.0527e-07 - Wnet_acc: 0.7526 - frozen_discriminator_acc: 1.0000 - val_loss: 0.7783 - val_Wnet_loss: 0.7783 - val_frozen_discriminator_loss: 7.1526e-07 - val_Wnet_acc: 0.6650 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4735 - Wnet_loss: 0.4735 - frozen_discriminator_loss: 6.6303e-07 - Wnet_acc: 0.7645 - frozen_discriminator_acc: 1.0000 - val_loss: 0.9232 - val_Wnet_loss: 0.9232 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6577 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.4627 - Wnet_loss: 0.4627 - frozen_discriminator_loss: 5.9202e-07 - Wnet_acc: 0.7725 - frozen_discriminator_acc: 1.0000 - val_loss: 0.9380 - val_Wnet_loss: 0.9380 - val_frozen_discriminator_loss: 7.7486e-07 - val_Wnet_acc: 0.6543 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4497 - Wnet_loss: 0.4497 - frozen_discriminator_loss: 5.9284e-07 - Wnet_acc: 0.7796 - frozen_discriminator_acc: 1.0000 - val_loss: 1.0044 - val_Wnet_loss: 1.0044 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6528 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4348 - Wnet_loss: 0.4348 - frozen_discriminator_loss: 5.7071e-07 - Wnet_acc: 0.7883 - frozen_discriminator_acc: 1.0000 - val_loss: 1.0511 - val_Wnet_loss: 1.0511 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6519 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.4198 - Wnet_loss: 0.4198 - frozen_discriminator_loss: 5.4099e-07 - Wnet_acc: 0.7957 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1180 - val_Wnet_loss: 1.1180 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6538 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4188 - Wnet_loss: 0.4188 - frozen_discriminator_loss: 4.7483e-07 - Wnet_acc: 0.8004 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1958 - val_Wnet_loss: 1.1958 - val_frozen_discriminator_loss: 1.7881e-07 - val_Wnet_acc: 0.5737 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.5249 - Wnet_loss: 0.5249 - frozen_discriminator_loss: 5.4918e-07 - Wnet_acc: 0.7616 - frozen_discriminator_acc: 1.0000 - val_loss: 0.9532 - val_Wnet_loss: 0.9532 - val_frozen_discriminator_loss: 7.1526e-07 - val_Wnet_acc: 0.6572 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4728 - Wnet_loss: 0.4728 - frozen_discriminator_loss: 4.3176e-07 - Wnet_acc: 0.7768 - frozen_discriminator_acc: 1.0000 - val_loss: 1.0443 - val_Wnet_loss: 1.0443 - val_frozen_discriminator_loss: 5.3644e-07 - val_Wnet_acc: 0.6597 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4434 - Wnet_loss: 0.4434 - frozen_discriminator_loss: 4.8973e-07 - Wnet_acc: 0.7886 - frozen_discriminator_acc: 1.0000 - val_loss: 0.9962 - val_Wnet_loss: 0.9962 - val_frozen_discriminator_loss: 5.9605e-07 - val_Wnet_acc: 0.6577 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4235 - Wnet_loss: 0.4235 - frozen_discriminator_loss: 5.1901e-07 - Wnet_acc: 0.7962 - frozen_discriminator_acc: 1.0000 - val_loss: 1.0797 - val_Wnet_loss: 1.0797 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6572 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4143 - Wnet_loss: 0.4143 - frozen_discriminator_loss: 4.9397e-07 - Wnet_acc: 0.8020 - frozen_discriminator_acc: 1.0000 - val_loss: 1.0949 - val_Wnet_loss: 1.0949 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6567 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4054 - Wnet_loss: 0.4054 - frozen_discriminator_loss: 4.9748e-07 - Wnet_acc: 0.8066 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1386 - val_Wnet_loss: 1.1386 - val_frozen_discriminator_loss: 5.9605e-07 - val_Wnet_acc: 0.6548 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3995 - Wnet_loss: 0.3995 - frozen_discriminator_loss: 4.7639e-07 - Wnet_acc: 0.8108 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1928 - val_Wnet_loss: 1.1928 - val_frozen_discriminator_loss: 6.5565e-07 - val_Wnet_acc: 0.6548 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3906 - Wnet_loss: 0.3906 - frozen_discriminator_loss: 1.1951e-07 - Wnet_acc: 0.8148 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2176 - val_Wnet_loss: 1.2176 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6553 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3839 - Wnet_loss: 0.3839 - frozen_discriminator_loss: 1.1951e-07 - Wnet_acc: 0.8192 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2130 - val_Wnet_loss: 1.2130 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6572 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4710 - Wnet_loss: 0.4710 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7920 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1618 - val_Wnet_loss: 1.1618 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6509 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4081 - Wnet_loss: 0.4081 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8110 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1375 - val_Wnet_loss: 1.1375 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6606 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3908 - Wnet_loss: 0.3908 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8180 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1292 - val_Wnet_loss: 1.1292 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6606 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3880 - Wnet_loss: 0.3880 - frozen_discriminator_loss: 1.1966e-07 - Wnet_acc: 0.8191 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1952 - val_Wnet_loss: 1.1952 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6558 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3767 - Wnet_loss: 0.3767 - frozen_discriminator_loss: 1.1936e-07 - Wnet_acc: 0.8236 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1919 - val_Wnet_loss: 1.1919 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6436 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3985 - Wnet_loss: 0.3985 - frozen_discriminator_loss: 1.2115e-07 - Wnet_acc: 0.8140 - frozen_discriminator_acc: 1.0000 - val_loss: 1.1067 - val_Wnet_loss: 1.1067 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6562 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3725 - Wnet_loss: 0.3725 - frozen_discriminator_loss: 1.1936e-07 - Wnet_acc: 0.8263 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2047 - val_Wnet_loss: 1.2047 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6519 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3637 - Wnet_loss: 0.3637 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8305 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2294 - val_Wnet_loss: 1.2294 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6455 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3586 - Wnet_loss: 0.3586 - frozen_discriminator_loss: 1.1928e-07 - Wnet_acc: 0.8338 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2610 - val_Wnet_loss: 1.2610 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6436 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3520 - Wnet_loss: 0.3520 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8363 - frozen_discriminator_acc: 1.0000 - val_loss: 1.2888 - val_Wnet_loss: 1.2888 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6475 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3453 - Wnet_loss: 0.3453 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8402 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3138 - val_Wnet_loss: 1.3138 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6460 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3392 - Wnet_loss: 0.3392 - frozen_discriminator_loss: 1.1928e-07 - Wnet_acc: 0.8433 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3326 - val_Wnet_loss: 1.3326 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6440 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3336 - Wnet_loss: 0.3336 - frozen_discriminator_loss: 1.1973e-07 - Wnet_acc: 0.8454 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3748 - val_Wnet_loss: 1.3748 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6436 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.3271 - Wnet_loss: 0.3271 - frozen_discriminator_loss: 1.1936e-07 - Wnet_acc: 0.8481 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3877 - val_Wnet_loss: 1.3877 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6401 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3433 - Wnet_loss: 0.3433 - frozen_discriminator_loss: 1.1936e-07 - Wnet_acc: 0.8418 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3859 - val_Wnet_loss: 1.3859 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6333 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3283 - Wnet_loss: 0.3283 - frozen_discriminator_loss: 1.1928e-07 - Wnet_acc: 0.8479 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3783 - val_Wnet_loss: 1.3783 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6348 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3189 - Wnet_loss: 0.3189 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8532 - frozen_discriminator_acc: 1.0000 - val_loss: 1.3915 - val_Wnet_loss: 1.3915 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6367 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3125 - Wnet_loss: 0.3125 - frozen_discriminator_loss: 1.1928e-07 - Wnet_acc: 0.8553 - frozen_discriminator_acc: 1.0000 - val_loss: 1.4795 - val_Wnet_loss: 1.4795 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6348 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3043 - Wnet_loss: 0.3043 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8593 - frozen_discriminator_acc: 1.0000 - val_loss: 1.4995 - val_Wnet_loss: 1.4995 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6348 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2970 - Wnet_loss: 0.2970 - frozen_discriminator_loss: 1.1928e-07 - Wnet_acc: 0.8616 - frozen_discriminator_acc: 1.0000 - val_loss: 1.5331 - val_Wnet_loss: 1.5331 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6318 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2891 - Wnet_loss: 0.2891 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8642 - frozen_discriminator_acc: 1.0000 - val_loss: 1.5878 - val_Wnet_loss: 1.5878 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6289 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2903 - Wnet_loss: 0.2903 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8635 - frozen_discriminator_acc: 1.0000 - val_loss: 1.6183 - val_Wnet_loss: 1.6183 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6299 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2817 - Wnet_loss: 0.2817 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8673 - frozen_discriminator_acc: 1.0000 - val_loss: 1.7009 - val_Wnet_loss: 1.7009 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6230 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2698 - Wnet_loss: 0.2698 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8695 - frozen_discriminator_acc: 1.0000 - val_loss: 1.7471 - val_Wnet_loss: 1.7471 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6196 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2630 - Wnet_loss: 0.2630 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8723 - frozen_discriminator_acc: 1.0000 - val_loss: 1.6968 - val_Wnet_loss: 1.6968 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6230 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2549 - Wnet_loss: 0.2549 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8742 - frozen_discriminator_acc: 1.0000 - val_loss: 1.7674 - val_Wnet_loss: 1.7674 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6226 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2500 - Wnet_loss: 0.2500 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8764 - frozen_discriminator_acc: 1.0000 - val_loss: 1.9066 - val_Wnet_loss: 1.9066 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6133 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2409 - Wnet_loss: 0.2409 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8736 - frozen_discriminator_acc: 1.0000 - val_loss: 1.8514 - val_Wnet_loss: 1.8514 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6035 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2365 - Wnet_loss: 0.2365 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8754 - frozen_discriminator_acc: 1.0000 - val_loss: 1.9362 - val_Wnet_loss: 1.9362 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6069 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2242 - Wnet_loss: 0.2242 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8746 - frozen_discriminator_acc: 1.0000 - val_loss: 1.9614 - val_Wnet_loss: 1.9614 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5986 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2640 - Wnet_loss: 0.2640 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8587 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0136 - val_Wnet_loss: 2.0136 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6108 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2236 - Wnet_loss: 0.2236 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8741 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0406 - val_Wnet_loss: 2.0406 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6001 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2130 - Wnet_loss: 0.2130 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8759 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0866 - val_Wnet_loss: 2.0866 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5986 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2042 - Wnet_loss: 0.2042 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8752 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0959 - val_Wnet_loss: 2.0959 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5981 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2074 - Wnet_loss: 0.2074 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8718 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1765 - val_Wnet_loss: 2.1765 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5840 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2136 - Wnet_loss: 0.2136 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8691 - frozen_discriminator_acc: 1.0000 - val_loss: 2.2261 - val_Wnet_loss: 2.2261 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5767 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.2320 - Wnet_loss: 0.2320 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8634 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0771 - val_Wnet_loss: 2.0771 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5835 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2096 - Wnet_loss: 0.2096 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8680 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1212 - val_Wnet_loss: 2.1212 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5820 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1929 - Wnet_loss: 0.1929 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8672 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1641 - val_Wnet_loss: 2.1641 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5820 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1811 - Wnet_loss: 0.1811 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8679 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5249 - val_Wnet_loss: 2.5249 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5718 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.4433 - Wnet_loss: 0.4433 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8027 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1234 - val_Wnet_loss: 2.1234 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5820 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2967 - Wnet_loss: 0.2967 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8391 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0375 - val_Wnet_loss: 2.0375 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6143 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2438 - Wnet_loss: 0.2438 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8657 - frozen_discriminator_acc: 1.0000 - val_loss: 2.0650 - val_Wnet_loss: 2.0650 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6147 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2218 - Wnet_loss: 0.2218 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8693 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1043 - val_Wnet_loss: 2.1043 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.6001 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2076 - Wnet_loss: 0.2076 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8713 - frozen_discriminator_acc: 1.0000 - val_loss: 2.1904 - val_Wnet_loss: 2.1904 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5981 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1975 - Wnet_loss: 0.1975 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8694 - frozen_discriminator_acc: 1.0000 - val_loss: 2.2310 - val_Wnet_loss: 2.2310 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5889 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1890 - Wnet_loss: 0.1890 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8715 - frozen_discriminator_acc: 1.0000 - val_loss: 2.2119 - val_Wnet_loss: 2.2119 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5913 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1829 - Wnet_loss: 0.1829 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8693 - frozen_discriminator_acc: 1.0000 - val_loss: 2.2851 - val_Wnet_loss: 2.2851 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5840 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1784 - Wnet_loss: 0.1784 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8666 - frozen_discriminator_acc: 1.0000 - val_loss: 2.3237 - val_Wnet_loss: 2.3237 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5845 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1774 - Wnet_loss: 0.1774 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8654 - frozen_discriminator_acc: 1.0000 - val_loss: 2.3305 - val_Wnet_loss: 2.3305 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5884 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1752 - Wnet_loss: 0.1752 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8655 - frozen_discriminator_acc: 1.0000 - val_loss: 2.3138 - val_Wnet_loss: 2.3138 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5820 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1666 - Wnet_loss: 0.1666 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8640 - frozen_discriminator_acc: 1.0000 - val_loss: 2.3525 - val_Wnet_loss: 2.3525 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5796 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1611 - Wnet_loss: 0.1611 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8620 - frozen_discriminator_acc: 1.0000 - val_loss: 2.3596 - val_Wnet_loss: 2.3596 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5776 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1582 - Wnet_loss: 0.1582 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8594 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4042 - val_Wnet_loss: 2.4042 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5757 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1542 - Wnet_loss: 0.1542 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8599 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4164 - val_Wnet_loss: 2.4164 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5737 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1500 - Wnet_loss: 0.1500 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8561 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4567 - val_Wnet_loss: 2.4567 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5684 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1671 - Wnet_loss: 0.1671 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8498 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5694 - val_Wnet_loss: 2.5694 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5566 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1645 - Wnet_loss: 0.1645 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8410 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4382 - val_Wnet_loss: 2.4382 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5679 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 101/120\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1517 - Wnet_loss: 0.1517 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8487 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4950 - val_Wnet_loss: 2.4950 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5649 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 102/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1441 - Wnet_loss: 0.1441 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8534 - frozen_discriminator_acc: 1.0000 - val_loss: 2.4543 - val_Wnet_loss: 2.4543 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5698 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 103/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1389 - Wnet_loss: 0.1389 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8501 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5603 - val_Wnet_loss: 2.5603 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5562 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 104/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1352 - Wnet_loss: 0.1352 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8487 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5840 - val_Wnet_loss: 2.5840 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5605 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 105/120\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1390 - Wnet_loss: 0.1390 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8471 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5977 - val_Wnet_loss: 2.5977 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5591 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 106/120\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1313 - Wnet_loss: 0.1313 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8402 - frozen_discriminator_acc: 1.0000 - val_loss: 2.5703 - val_Wnet_loss: 2.5703 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5571 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 107/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1362 - Wnet_loss: 0.1362 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8432 - frozen_discriminator_acc: 1.0000 - val_loss: 2.6257 - val_Wnet_loss: 2.6257 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5591 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 108/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1257 - Wnet_loss: 0.1257 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8400 - frozen_discriminator_acc: 1.0000 - val_loss: 2.6692 - val_Wnet_loss: 2.6692 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5581 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 109/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1248 - Wnet_loss: 0.1248 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8401 - frozen_discriminator_acc: 1.0000 - val_loss: 2.6587 - val_Wnet_loss: 2.6587 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5527 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 110/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1181 - Wnet_loss: 0.1181 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8329 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7501 - val_Wnet_loss: 2.7501 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5488 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 111/120\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1174 - Wnet_loss: 0.1174 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8297 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7032 - val_Wnet_loss: 2.7032 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5479 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 112/120\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1138 - Wnet_loss: 0.1138 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8286 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8118 - val_Wnet_loss: 2.8118 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5420 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 113/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1075 - Wnet_loss: 0.1075 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8278 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8151 - val_Wnet_loss: 2.8151 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5425 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 114/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1029 - Wnet_loss: 0.1029 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8220 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8508 - val_Wnet_loss: 2.8508 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5347 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 115/120\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1023 - Wnet_loss: 0.1023 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8215 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7804 - val_Wnet_loss: 2.7804 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5332 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 116/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1284 - Wnet_loss: 0.1284 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8063 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6723 - val_Wnet_loss: 3.6723 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4561 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 117/120\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2598 - Wnet_loss: 0.2598 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7600 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9053 - val_Wnet_loss: 2.9053 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5225 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 118/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1740 - Wnet_loss: 0.1740 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7868 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8362 - val_Wnet_loss: 2.8362 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5200 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 119/120\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1471 - Wnet_loss: 0.1471 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8002 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8379 - val_Wnet_loss: 2.8379 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5410 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 120/120\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1317 - Wnet_loss: 0.1317 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8084 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8619 - val_Wnet_loss: 2.8619 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5420 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 121/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1230 - Wnet_loss: 0.1230 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8178 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8257 - val_Wnet_loss: 2.8257 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5439 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 122/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1170 - Wnet_loss: 0.1170 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8147 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8723 - val_Wnet_loss: 2.8723 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5386 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 123/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1099 - Wnet_loss: 0.1099 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8173 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8983 - val_Wnet_loss: 2.8983 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5410 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 124/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2210 - Wnet_loss: 0.2210 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7801 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7079 - val_Wnet_loss: 2.7079 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5273 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 125/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1674 - Wnet_loss: 0.1674 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8041 - frozen_discriminator_acc: 1.0000 - val_loss: 2.6361 - val_Wnet_loss: 2.6361 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5430 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 126/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1433 - Wnet_loss: 0.1433 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8129 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7021 - val_Wnet_loss: 2.7021 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5430 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 127/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1345 - Wnet_loss: 0.1345 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8119 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7298 - val_Wnet_loss: 2.7298 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5352 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 128/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1244 - Wnet_loss: 0.1244 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8095 - frozen_discriminator_acc: 1.0000 - val_loss: 2.7779 - val_Wnet_loss: 2.7779 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5347 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 129/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1152 - Wnet_loss: 0.1152 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8098 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8202 - val_Wnet_loss: 2.8202 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5283 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 130/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1109 - Wnet_loss: 0.1109 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8099 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8301 - val_Wnet_loss: 2.8301 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5273 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 131/140\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1076 - Wnet_loss: 0.1076 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8073 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8036 - val_Wnet_loss: 2.8036 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5298 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 132/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1032 - Wnet_loss: 0.1032 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8095 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8603 - val_Wnet_loss: 2.8603 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5195 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 133/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1008 - Wnet_loss: 0.1008 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8023 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8701 - val_Wnet_loss: 2.8701 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5186 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 134/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1027 - Wnet_loss: 0.1027 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8087 - frozen_discriminator_acc: 1.0000 - val_loss: 2.8827 - val_Wnet_loss: 2.8827 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5332 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 135/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0957 - Wnet_loss: 0.0957 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8061 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9060 - val_Wnet_loss: 2.9060 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5215 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 136/140\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0972 - Wnet_loss: 0.0972 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8023 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9062 - val_Wnet_loss: 2.9062 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5117 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 137/140\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0939 - Wnet_loss: 0.0939 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8038 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9130 - val_Wnet_loss: 2.9130 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5137 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 138/140\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0902 - Wnet_loss: 0.0902 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7984 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9228 - val_Wnet_loss: 2.9228 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5142 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 139/140\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0880 - Wnet_loss: 0.0880 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.8002 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9195 - val_Wnet_loss: 2.9195 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5142 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 140/140\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0862 - Wnet_loss: 0.0862 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7979 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9422 - val_Wnet_loss: 2.9422 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5088 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 141/160\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0834 - Wnet_loss: 0.0834 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7925 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9207 - val_Wnet_loss: 2.9207 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5083 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 142/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0816 - Wnet_loss: 0.0816 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7945 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9523 - val_Wnet_loss: 2.9523 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5083 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 143/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0800 - Wnet_loss: 0.0800 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7888 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9537 - val_Wnet_loss: 2.9537 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5039 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 144/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0818 - Wnet_loss: 0.0818 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7877 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9935 - val_Wnet_loss: 2.9935 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5059 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 145/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0795 - Wnet_loss: 0.0795 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7796 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9878 - val_Wnet_loss: 2.9878 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5010 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 146/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0750 - Wnet_loss: 0.0750 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7829 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9718 - val_Wnet_loss: 2.9718 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.5005 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 147/160\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0725 - Wnet_loss: 0.0725 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7785 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9911 - val_Wnet_loss: 2.9911 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4966 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 148/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0707 - Wnet_loss: 0.0707 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7766 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0018 - val_Wnet_loss: 3.0018 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4946 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 149/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0687 - Wnet_loss: 0.0687 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7724 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0127 - val_Wnet_loss: 3.0127 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4922 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 150/160\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0697 - Wnet_loss: 0.0697 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7710 - frozen_discriminator_acc: 1.0000 - val_loss: 3.2767 - val_Wnet_loss: 3.2767 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4907 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 151/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1059 - Wnet_loss: 0.1059 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7586 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0022 - val_Wnet_loss: 3.0022 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4917 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 152/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0717 - Wnet_loss: 0.0717 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7676 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9735 - val_Wnet_loss: 2.9735 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4971 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 153/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0674 - Wnet_loss: 0.0674 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7681 - frozen_discriminator_acc: 1.0000 - val_loss: 2.9816 - val_Wnet_loss: 2.9816 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4971 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 154/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0640 - Wnet_loss: 0.0640 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7624 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0204 - val_Wnet_loss: 3.0204 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4937 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 155/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0619 - Wnet_loss: 0.0619 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7610 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0018 - val_Wnet_loss: 3.0018 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4883 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 156/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0599 - Wnet_loss: 0.0599 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7556 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0068 - val_Wnet_loss: 3.0068 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4849 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 157/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0580 - Wnet_loss: 0.0580 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7524 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0652 - val_Wnet_loss: 3.0652 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4844 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 158/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0560 - Wnet_loss: 0.0560 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7489 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0620 - val_Wnet_loss: 3.0620 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4824 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 159/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0538 - Wnet_loss: 0.0538 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7486 - frozen_discriminator_acc: 1.0000 - val_loss: 3.0896 - val_Wnet_loss: 3.0896 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4922 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 160/160\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0556 - Wnet_loss: 0.0556 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7491 - frozen_discriminator_acc: 1.0000 - val_loss: 3.1206 - val_Wnet_loss: 3.1206 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4775 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 161/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0520 - Wnet_loss: 0.0520 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7386 - frozen_discriminator_acc: 1.0000 - val_loss: 3.1233 - val_Wnet_loss: 3.1233 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4736 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 162/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0498 - Wnet_loss: 0.0498 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7348 - frozen_discriminator_acc: 1.0000 - val_loss: 3.1858 - val_Wnet_loss: 3.1858 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4736 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 163/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0485 - Wnet_loss: 0.0485 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7349 - frozen_discriminator_acc: 1.0000 - val_loss: 3.1935 - val_Wnet_loss: 3.1935 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4624 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 164/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0466 - Wnet_loss: 0.0466 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7303 - frozen_discriminator_acc: 1.0000 - val_loss: 3.1755 - val_Wnet_loss: 3.1755 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4624 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 165/180\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0447 - Wnet_loss: 0.0447 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7249 - frozen_discriminator_acc: 1.0000 - val_loss: 3.2075 - val_Wnet_loss: 3.2075 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4634 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 166/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0438 - Wnet_loss: 0.0438 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7260 - frozen_discriminator_acc: 1.0000 - val_loss: 3.2345 - val_Wnet_loss: 3.2345 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4624 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 167/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0423 - Wnet_loss: 0.0423 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7198 - frozen_discriminator_acc: 1.0000 - val_loss: 3.2470 - val_Wnet_loss: 3.2470 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4668 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 168/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0415 - Wnet_loss: 0.0415 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7183 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3164 - val_Wnet_loss: 3.3164 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4604 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 169/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0425 - Wnet_loss: 0.0425 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7054 - frozen_discriminator_acc: 1.0000 - val_loss: 3.2986 - val_Wnet_loss: 3.2986 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4648 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 170/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0393 - Wnet_loss: 0.0393 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7091 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3157 - val_Wnet_loss: 3.3157 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4556 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 171/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0371 - Wnet_loss: 0.0371 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7048 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3276 - val_Wnet_loss: 3.3276 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4634 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 172/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0362 - Wnet_loss: 0.0362 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.7017 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3480 - val_Wnet_loss: 3.3480 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4521 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 173/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0337 - Wnet_loss: 0.0337 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6941 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3772 - val_Wnet_loss: 3.3772 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4492 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 174/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0322 - Wnet_loss: 0.0322 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6901 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4081 - val_Wnet_loss: 3.4081 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4468 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 175/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0311 - Wnet_loss: 0.0311 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6875 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4229 - val_Wnet_loss: 3.4229 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4512 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 176/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0299 - Wnet_loss: 0.0299 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6856 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4231 - val_Wnet_loss: 3.4231 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4531 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 177/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0294 - Wnet_loss: 0.0294 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6810 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3984 - val_Wnet_loss: 3.3984 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4473 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 178/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0280 - Wnet_loss: 0.0280 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6814 - frozen_discriminator_acc: 1.0000 - val_loss: 3.3776 - val_Wnet_loss: 3.3776 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4497 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 179/180\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0530 - Wnet_loss: 0.0530 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6737 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6975 - val_Wnet_loss: 3.6975 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4199 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 180/180\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0597 - Wnet_loss: 0.0597 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6676 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5007 - val_Wnet_loss: 3.5007 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4385 - val_frozen_discriminator_acc: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0377 - Wnet_loss: 0.0377 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6728 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4714 - val_Wnet_loss: 3.4714 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4419 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0316 - Wnet_loss: 0.0316 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6670 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5064 - val_Wnet_loss: 3.5064 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4399 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0302 - Wnet_loss: 0.0302 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6714 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5470 - val_Wnet_loss: 3.5470 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4409 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0268 - Wnet_loss: 0.0268 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6626 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5549 - val_Wnet_loss: 3.5549 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4390 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0253 - Wnet_loss: 0.0253 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6628 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5360 - val_Wnet_loss: 3.5360 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4365 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0246 - Wnet_loss: 0.0246 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6615 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4691 - val_Wnet_loss: 3.4691 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4365 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0231 - Wnet_loss: 0.0231 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6541 - frozen_discriminator_acc: 1.0000 - val_loss: 3.4620 - val_Wnet_loss: 3.4620 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4365 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0316 - Wnet_loss: 0.0316 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6614 - frozen_discriminator_acc: 1.0000 - val_loss: 3.8390 - val_Wnet_loss: 3.8390 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4292 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0759 - Wnet_loss: 0.0759 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6766 - frozen_discriminator_acc: 1.0000 - val_loss: 3.5669 - val_Wnet_loss: 3.5669 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4346 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0407 - Wnet_loss: 0.0407 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6518 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6269 - val_Wnet_loss: 3.6269 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4302 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0317 - Wnet_loss: 0.0317 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6467 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6241 - val_Wnet_loss: 3.6241 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4331 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0274 - Wnet_loss: 0.0274 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6453 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6165 - val_Wnet_loss: 3.6165 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4312 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0246 - Wnet_loss: 0.0246 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6409 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6457 - val_Wnet_loss: 3.6457 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4272 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0229 - Wnet_loss: 0.0229 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6397 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6336 - val_Wnet_loss: 3.6336 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4292 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0218 - Wnet_loss: 0.0218 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6374 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6252 - val_Wnet_loss: 3.6252 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4253 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0224 - Wnet_loss: 0.0224 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6362 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6123 - val_Wnet_loss: 3.6123 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4248 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0201 - Wnet_loss: 0.0201 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6344 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6180 - val_Wnet_loss: 3.6180 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4307 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0190 - Wnet_loss: 0.0190 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6321 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6114 - val_Wnet_loss: 3.6114 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4277 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0184 - Wnet_loss: 0.0184 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6269 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6319 - val_Wnet_loss: 3.6319 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4233 - val_frozen_discriminator_acc: 1.0000\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0175 - Wnet_loss: 0.0175 - frozen_discriminator_loss: 1.1921e-07 - Wnet_acc: 0.6241 - frozen_discriminator_acc: 1.0000 - val_loss: 3.6531 - val_Wnet_loss: 3.6531 - val_frozen_discriminator_loss: 1.1921e-07 - val_Wnet_acc: 0.4263 - val_frozen_discriminator_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "myModel.fit_wnet_cgan(X=[dsm,pan,label], Y=[label,np.ones(shape=(len(label),1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = myModel.wnet.predict([dsm[i:i+1],pan[i:i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = ppp[0,...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp[pp<0.7] = 0\n",
    "pp[pp>=0.7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287fd1b1a58>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skimage.io.imshow(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287fd1f4128>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEI9JREFUeJzt3W+IXNd9xvHnqSMnJTbEqmRVldXKDqZElET2LsKQENK0CY4p2IY22NBgqEGhxCWB9IVIoXFbCklpbPKipMi1iVpc/2lsY78IaYxw6waKk1lXlmVE6z+ojSwhydgh7puksn99MVftRt6ZOzt37u+cmf1+YNnZuzP3/ubM6tGde86c44gQAPTt50oXAGBjIGwApCBsAKQgbACkIGwApCBsAKQgbACkIGwApCBsAKR4V+bBtmzZErt27Rr5+5WVlbxiVllaWupt323Pqe3YXR/fZd9ddHlefbZJrc95Fo8v6LWI2Np2J3f5uILt6yV9XdJFkv4mIr4y7v7Ly8sxGAzG7W/qWrro8yMbbc+p7dhdH99l3110eV59tkmtz3kWjy9oJSKW2+409dso2xdJ+itJn5K0W9KttndPuz8Ai63LNZu9kl6KiFci4qeSHpR042zKArBouoTNDkk/XPXziWbbz7C9z/bA9uDs2bMdDgdgnnUJm7XeQL7jTWdEHIiI5YhY3rq19RoSgAXVJWxOSNq56ucrJJ3sVg6ARdUlbH4g6WrbV9q+WNItkp6YTVkAFs3U42wi4pztOyT9o4Zd3/dFxAvjHrOyslJl913JLsk+26PGtj6vS/d0n0MVurzWXdu71tdrVn//ncbZrJftuZyDtObxD6XGlLTpc/xPyX3XGgh9mqBN+h1nAwDrQdgASEHYAEhB2ABIQdgASJE6xUQXffYSzHMPRK2flC/ZpV+qt6rv16LUJ/xn9bw4swGQgrABkIKwAZCCsAGQgrABkIKwAZCCsAGQYm7G2XTV5/iIWj95Pa9KTiHRpsuqEF32Pcnva8eZDYAUhA2AFIQNgBSEDYAUhA2AFIQNgBSEDYAUVY2zmdfxKn3OpVPy2H0uWzLtcaVudXedh6fWJWjalGyz8zizAZCCsAGQgrABkIKwAZCCsAGQgrABkKKqru9SXcglu0NLdunP6/I3JZcl6fPYJds0Y9hJp7CxfVzSm5LeknQuIpZnURSAxTOLM5tfj4jXZrAfAAuMazYAUnQNm5D0XdsrtvetdQfb+2wPbA86HgvAHHPH9YN/KSJO2r5c0pOS/iAinh5z/94+HNLn505qXv+5lHleH71WJdez73jclUmu13Y6s4mIk833M5Iek7S3y/4ALK6pw8b2e21fev62pE9KOjqrwgAsli69UdskPdacYr1L0t9HxHdmUtUU5nWahzZzfGo99bE36luwmqftmIWpwyYiXpH0oRnWAmCB0fUNIAVhAyAFYQMgBWEDIAVhAyAFYQMgRVXz2YzT53iTmpcO6aLkGJ2a5/EZp+bXa5yS8/RMijMbACkIGwApCBsAKQgbACkIGwApCBsAKeam63telzzpu0syY2qAafTZjdvnvvuclbHm2Q0zpvzgzAZACsIGQArCBkAKwgZACsIGQArCBkAKwgZAitRxNktLSxoMRq/C22Wqhi7meXxErW3Wpuba+tp3yTbrMr5oVn//nNkASEHYAEhB2ABIQdgASEHYAEhB2ABIQdgASNE6zsb2fZJ+S9KZiPi1ZttmSQ9J2iXpuKRPR8Qb/ZVZ7xIafSu5vMc4Jcce1boMTN9KvZ6Z89l8U9L1F2zbL+lQRFwt6VDzMwCM1Bo2EfG0pNcv2HyjpIPN7YOSbppxXQAWzLTXbLZFxClJar5fPruSACyi3i8Q295ne2B7cPbs2b4PB6BS04bNadvbJan5fmbUHSPiQEQsR8Ty1q1bpzwcgHk3bdg8Iem25vZtkh6fTTkAFlVr2Nh+QNK/SvpV2yds3y7pK5I+YftFSZ9ofgaAkZw5xsT22IOVWmuoz3lGNuqYkDaMH6rr2B2tRMRy250YQQwgBWEDIAVhAyAFYQMgBWEDIAVhAyBFVUu5jNO126/WKQ+6dncuYpf+onYv1/xaZ+DMBkAKwgZACsIGQArCBkAKwgZACsIGQArCBkCKqqaY6KLLGIaaxz/0+bzazGubTXvcSczDeJa19Dy+iCkmANSDsAGQgrABkIKwAZCCsAGQgrABkIKwAZCiqvls+hwzUquSz6vW8Swl55ypdXxQm3lYBoYzGwApCBsAKQgbACkIGwApCBsAKQgbACmYYmID6/O1r3lJlL70PX1Fl273uZhiwvZ9ts/YPrpq2522X7V9uPm6oUulABbfJG+jvinp+jW23x0Re5qvb8+2LACLpjVsIuJpSa8n1AJggXW5QHyH7SPN26zLRt3J9j7bA9vTrbsLYCFMGzbfkPR+SXsknZL0tVF3jIgDEbE8yQUkAItrqrCJiNMR8VZEvC3pHkl7Z1sWgEUzVdjY3r7qx5slHR11XwCQJphiwvYDkj4maYvtE5K+LOljtvdICknHJX12koN1mWJigjqnfmybWsd1dDWvddeq61iXrvvv8tiMqTNawyYibl1j870zOTqADYOPKwBIQdgASEHYAEhB2ABIQdgASEHYAEixMPPZYPa6/G10GZtR8zw7tS7l0qbnNp3NfDYAMAuEDYAUhA2AFIQNgBSEDYAUhA2AFK2f+p6ltikmxtmoXZZt+nxe4x5fc/c03qmGNuXMBkAKwgZACsIGQArCBkAKwgZACsIGQArCBkCKuZliouRyKn0ee16XieH1mL1SU3q0maBNmGICQD0IGwApCBsAKQgbACkIGwApCBsAKQgbACla57OxvVPS30r6RUlvSzoQEV+3vVnSQ5J2STou6dMR8UZ/pZbTNoahzzllah17UXL8z7w+r65j2rrML9Tlb3hWJjmzOSfpixHxAUnXSfqc7d2S9ks6FBFXSzrU/AwAa2oNm4g4FRHPNrfflHRM0g5JN0o62NztoKSb+ioSwPxb17SgtndJukbSM5K2RcQpaRhIti8f8Zh9kvZ1KxPAvJs4bGxfIukRSV+IiB9P+t42Ig5IOtDsg+V3gQ1qot4o25s0DJr7I+LRZvNp29ub32+XdKafEgEsgtaw8fAU5l5JxyLirlW/ekLSbc3t2yQ9PvvyACyK1ikmbH9E0r9Iel7Drm9J+pKG120elvTLkv5L0u9ExOst+yr2NqpUF3LJLslap6foW6mhCF1fyzn+W5hoionWazYR8T1Joyr9jfVWBWBjYgQxgBSEDYAUhA2AFIQNgBSEDYAUhA2AFOv6bFTfSo1h6PPj9X1/tH+jjqUZp8+pGPrcd5tSf8Ozel6c2QBIQdgASEHYAEhB2ABIQdgASEHYAEhB2ABIkTrOZmlpSYPBYOTva15GY9p99zm2ok2f86fM6/iekkvr9KnPcWizeq05swGQgrABkIKwAZCCsAGQgrABkIKwAZBiYaaYaDOvXbVdzHO3exd9TlXSRck2qeHvnzMbACkIGwApCBsAKQgbACkIGwApCBsAKQgbACmc+ZF522MP1uc4my7Ps8+pGPoce8EyMbNX67QbfU4n0sb2SkQst92v9czG9k7bT9k+ZvsF259vtt9p+1Xbh5uvG6auFsDCm2QE8TlJX4yIZ21fKmnF9pPN7+6OiL/srzwAi6I1bCLilKRTze03bR+TtKPvwgAslnVdILa9S9I1kp5pNt1h+4jt+2xfNuIx+2wPbI+eDxTAwpv4ArHtSyT9s6Q/j4hHbW+T9JqkkPRnkrZHxO+17IMLxOt47CSP77LvNlwgficuEK+579lcIG52tknSI5Luj4hHm+JOR8RbEfG2pHsk7Z26WgALb5LeKEu6V9KxiLhr1fbtq+52s6Sjsy8PwKKYpDfqw5I+I+l524ebbV+SdKvtPRq+jTou6bO9VDgj8/qWoM9xUCWXcunzbW0XJeec6aLk2/VJTdIb9T1Ja1Xy7dmXA2BR8XEFACkIGwApCBsAKQgbACkIGwApCBsAKapaN6rWMQxtutRdcsxIm0Vcx6iG8SZ9mIfnxZkNgBSEDYAUhA2AFIQNgBSEDYAUhA2AFFV1fY9TczdunzP1tRm3/5qnHVjEmRP7bs95n/KDMxsAKQgbACkIGwApCBsAKQgbACkIGwApCBsAKVLH2SwtLWkwGL0Kb5cxI30qOR6lzzElNUw7sJaudc3rlB99rn5aw2vNmQ2AFIQNgBSEDYAUhA2AFIQNgBSEDYAUhA2AFK3jbGy/R9LTkt7d3P9bEfFl21dKelDSZknPSvpMRPy0SzEZc2pMc9yax/jMqxrGfUyjzzlluig5NmlSk5zZ/ETSxyPiQ5L2SLre9nWSvirp7oi4WtIbkm7vr0wA8641bGLov5sfNzVfIenjkr7VbD8o6aZeKgSwECa6ZmP7ItuHJZ2R9KSklyX9KCLONXc5IWnHiMfusz2wPTh79uwsagYwhyYKm4h4KyL2SLpC0l5JH1jrbiMeeyAiliNieevWrdNXCmCuras3KiJ+JOmfJF0n6X22z19gvkLSydmWBmCRtIaN7a2239fc/nlJvynpmKSnJP12c7fbJD3eV5EA5p8n6Pb9oIYXgC/SMJwejog/tX2V/r/r+98k/W5E/KRlX4vZj1upPpeJKTldQpta6655+oqOXforEbHcdqfWsJklwibXov6jbVNr3Rs9bBhBDCAFYQMgBWEDIAVhAyAFYQMgBWEDIEXqUi6SXpP0n6t+3tJsq02tdUnrqC15iZmZtdmM6/6Zukouu7OGatrsgsevt65fmegYJedLsT2YpH8+W611SfXWRl3rV2ttfdXF2ygAKQgbAClKh82Bwscfpda6pHpro671q7W2Xuoqes0GwMZR+swGwAZB2ABIUSRsbF9v+99tv2R7f4kaRrF93Pbztg/bHhSs4z7bZ2wfXbVts+0nbb/YfL+sotrutP1q026Hbd9QoK6dtp+yfcz2C7Y/32wv2m5j6qqhzd5j+/u2n2tq+5Nm+5W2n2na7CHbF3c+WESkfmk4CdfLkq6SdLGk5yTtzq5jTH3HJW2poI6PSrpW0tFV2/5C0v7m9n5JX62otjsl/WHhNtsu6drm9qWS/kPS7tLtNqauGtrMki5pbm+S9IyG0/4+LOmWZvtfS/r9rscqcWazV9JLEfFKDBe1e1DSjQXqqFpEPC3p9Qs236jhrIlSweVzRtRWXESciohnm9tvajh97Q4VbrcxdRUXQylLNZUImx2Sfrjq55HLwBQSkr5re8X2vtLFXGBbRJyShn/Aki4vXM+F7rB9pHmbVeQt3nm2d0m6RsP/qatptwvqkiposy5LNa1HibBZ60McNfW/fzgirpX0KUmfs/3R0gXNiW9Ier+Gq6aekvS1UoXYvkTSI5K+EBE/LlXHhdaoq4o2iw5LNa1HibA5IWnnqp+rWgYmIk42389IekzDxq/FadvbJan5fqZwPf8nIk43f7RvS7pHhdrN9iYN/0HfHxGPNpuLt9taddXSZudFz0s1lQibH0i6urnafbGkWyQ9UaCOd7D9XtuXnr8t6ZOSjo5/VKonNFw2R6ps+Zzz/5gbN6tAu3n40eV7JR2LiLtW/apou42qq5I2y1uqqdAV8Bs0vCL/sqQ/Knk1/oK6rtKwd+w5SS+UrE3SAxqeWv+PhmeDt0v6BUmHJL3YfN9cUW1/J+l5SUc0/Me9vUBdH9HwdP+IpMPN1w2l221MXTW02Qc1XIrpiIZh98fN9qskfV/SS5L+QdK7ux6LjysASMEIYgApCBsAKQgbACkIGwApCBsAKQgbACkIGwAp/hegTLG/B9cGeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skimage.io.imshow(label[i,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pp==label[i,...,0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
